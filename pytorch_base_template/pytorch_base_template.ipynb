{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Base Template\n",
    "\n",
    "### MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 0.001,\n",
    "    \"epochs\": 10,\n",
    "    \"num_workers\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83004821 0.66853652 0.87390994 0.25807092 0.76774931]\n",
      " [0.11565201 0.37706954 0.96101122 0.79003733 0.69426307]\n",
      " [0.7363972  0.59160882 0.91935905 0.87357674 0.51348941]\n",
      " ...\n",
      " [0.53159385 0.6996126  0.93819342 0.42920674 0.03848498]\n",
      " [0.71062043 0.94355812 0.4718376  0.72504445 0.10582   ]\n",
      " [0.91097073 0.31684282 0.98655006 0.63437644 0.0784837 ]]\n",
      "(600,)\n",
      "(200,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "samples = np.random.rand(1000, 5)\n",
    "train_idx = np.arange(600)\n",
    "val_idx = np.arange(600, 800)\n",
    "test_idx = np.arange(800, 1000)\n",
    "print(samples)\n",
    "print(train_idx.shape)\n",
    "print(val_idx.shape)\n",
    "print(test_idx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.8300, 0.6685, 0.8739, 0.2581]), tensor([0.7677]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx][:4]\n",
    "        label = self.samples[idx][4:]\n",
    "\n",
    "        sample, label = torch.tensor(sample).float(), torch.tensor(label).float()\n",
    "        return sample, label\n",
    "\n",
    "\n",
    "dataset = Data(samples)\n",
    "example_input, example_target = dataset[0]\n",
    "example_input, example_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = {\n",
    "    \"train\": DataLoader(dataset, sampler=train_idx, batch_size=CFG[\"batch_size\"], shuffle=False, num_workers=CFG[\"num_workers\"], pin_memory=True),\n",
    "    \"val\": DataLoader(dataset, sampler=val_idx, batch_size=CFG[\"batch_size\"], shuffle=False, num_workers=CFG[\"num_workers\"], pin_memory=True),\n",
    "    \"test\": DataLoader(dataset, sampler=test_idx, batch_size=CFG[\"batch_size\"], shuffle=False, num_workers=CFG[\"num_workers\"], pin_memory=True)  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(4, 4),\n",
    "            nn.BatchNorm1d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 4),\n",
    "            nn.BatchNorm1d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) VAL \t train_loss=1.01 \t val_loss=0.74\n",
      "(2) VAL \t train_loss=0.84 \t val_loss=0.75\n",
      "(3) VAL \t train_loss=0.71 \t val_loss=0.70\n",
      "(4) VAL \t train_loss=0.61 \t val_loss=0.62\n",
      "(5) VAL \t train_loss=0.54 \t val_loss=0.55\n",
      "(6) VAL \t train_loss=0.47 \t val_loss=0.49\n",
      "(7) VAL \t train_loss=0.42 \t val_loss=0.44\n",
      "(8) VAL \t train_loss=0.38 \t val_loss=0.41\n",
      "(9) VAL \t train_loss=0.34 \t val_loss=0.37\n",
      "(10) VAL \t train_loss=0.31 \t val_loss=0.35\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=CFG[\"lr\"])\n",
    "\n",
    "for epoch in range(CFG[\"epochs\"]):\n",
    "    history = {\n",
    "            \"train_loss\": [],\n",
    "            \"val_loss\": []\n",
    "    }\n",
    "\n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        if phase == \"train\":\n",
    "            net.train()\n",
    "        else:\n",
    "            net.eval()\n",
    "\n",
    "        for inputs, labels in data_loader[phase]:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            history[f\"{phase}_loss\"].append(loss.item())\n",
    "\n",
    "    mean_train_loss = np.mean(history[\"train_loss\"])\n",
    "    mean_val_loss = np.mean(history[\"val_loss\"])\n",
    "    print(f\"({epoch+1}) {phase.upper()} \\t train_loss={mean_train_loss:.2f} \\t val_loss={mean_val_loss:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
